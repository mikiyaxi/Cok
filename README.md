

## To-Do 
- [ ] *variational inference*: [1](https://www.youtube.com/watch?v=HxQ94L8n0vU), [2](https://www.youtube.com/watch?v=UTMpM4orS30) | *reparameterization [trick]()*
- [ ] *multi-gpu training: accelerate* [github example](https://github.com/huggingface/accelerate), [reading](https://wandb.ai/wandb_fc/pytorch-image-models/reports/An-Introduction-to-HuggingFace-s-Accelerate-Library--Vmlldzo2MzgzNzA), [video](https://www.youtube.com/watch?v=A7lnu-ZsFZs) | [DDP](https://www.youtube.com/watch?v=Cvdhwx-OBBo&list=PL_lsbAsL_o2CSuhUhJIiW0IkdT5C2wGWj&index=2)
- [ ] *ResNet: concept* [1](https://www.youtube.com/watch?v=ZILIbUvp5lk) | [2](https://www.youtube.com/watch?v=RYth6EbBUqM) | [3](https://www.youtube.com/watch?v=GWt6Fu05voI) | [4](https://www.youtube.com/watch?v=o_3mboe1jYI) <br>
- [ ] *stock/finance related project*: ["real-time stock price tracker web/python"](https://www.youtube.com/watch?v=GSHFzqqPq5U) <br>
- [ ] *Plotly:* [link](https://www.youtube.com/watch?v=2P1e5wtOhCA) <br>


## Idea
- [ ] Creating New Music/Audio clips
    - *beyond something we had heard before*
    - *ability to compose new music pieces, ability to learn sound/music logic*
    - *forget training data as much as possible, don't copy paste or simply recombine*
- [ ] LAION.AI (use their idea or model or dataset)
    - *CLIP*
    - *CLAP*
- [ ] Learning Order 
    - *why human can learn with few samples, but machine need to be trained with a lot?*
    - *for example, for a musician to be able to compose, or play what we human does it that we practice something with basic from the beginning. Take myself for example, when I was learning piano, I started with pieces like Hanon(哈农), Beyer(拜厄), Czerny(车尔尼) 599/849/299/etc, Chopin Études(肖邦练习曲), etc. When I spend some years get familiar with those scale(音阶) and practice song(练习曲), it's very easy for me to learning new pieces, either classic, jazz or pop. So another way of thinking AI and neural network, currently the training set we feed in is the finished products(pop song, or fluent speech), what about feeing the model starting from basic components. Complex song and lyrics are consitituted with different components in combination of scale and practice song or etc, so how about letting nn learn those basic first?*
    - *for speech, how about let the model learn the logic of grammar, instead of billions of sentences. Can we prefixed the grammar or language context as a pre-algorithm before they are learning real examples? Not something simple like the prompt, I am thinking about something more complex, like the model remember the rules likes "is" is followed after "he/she/it", is that possible?*


## AI 
&#x237e; *Machine Learning*
- *[math](./AI/Machine_Learning/math/)*
- *[model](./AI/Machine_Learning/model/)*
<br>


&#x237e; *Neural Network*
- *math*
- *cnn*
<br>


&#x237e; *Algorithm*
- *fundamental: [toc](./AI/Algorithm/fundamental/theory-of-computation.md)*
- *data structure: [basic](./AI/Algorithm/data_structure/dataStructureBasic.md)/[advance](./AI/Algorithm/data_structure/dataStructureAdvanced.md)*
- *[search](./AI/Algorithm/search/)*
- *[sort](./AI/Algorithm/sort/)*
<br>


## System
&#x237e; *architecture* 
- *database: [relational](./System/architecture/database/Rdesign.md)*
- *computer: [co](./System/architecture/co/computer-organization.md)*
<br>


&#x237e; *operating system*
- *programing: [C]()/[C++](./System/OS/C++/conceptC++.md)*
<br>


## Utils 
&#x237e; *General*: [check]()


## Resource 
*speech recognition: [OpenSLR](https://www.openslr.org/index.html)* <br>
*3D visualization: [TensorSpace.js](https://tensorspace.org/index.html)* | 


